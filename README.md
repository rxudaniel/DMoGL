# DMoGL
Hotspot detection constitutes a critical task in text analysis, yet existing methodologies face challenges in simultaneously mitigating hotspot fragmentation and enhancing semantic precision. Frequent pattern mining approaches tend to extract fragmented short-term terms, while topic modeling-based methods struggle to maintain coherent semantics by representing hotspots through multiple disjointed terms. To address these limitations, this paper introduces the concept of "long-text hotspot detection" (a novel task tailored for Chinese news corpora) aimed at identifying semantically richer hotspots with extended text spans from large-scale news headlines. We propose DMoGL (Deep Mining of Long-text Hotspots based on Global-Local Fusion), a lightweight model that innovatively constructs a word-adjacency table to jointly model co-occurrence relationships among documents and between documents and dictionaries. The framework integrates frequent pattern mining strategies with a semantic-enhanced fusion mechanism, where global mining identifies hotspot clues while local mining captures detailed contextual information. Experimental validation is conducted on a manually annotated Chinese news headline dataset, with comparative experiments against baseline models including Gensim-ngram, BERTopic-TF-IDF, Top2Vec-BERT, and Chinese large language models Qwen_plus/GLM-4-plus. Results demonstrate DMoGL's robust performance across varying support thresholds, maintaining stable precision (97.3%, 7.8–15.5% higher than baselines), recall (93.5%, 34.7–41.4% improvement), and F1 (95.4%, 26.6–34.6% enhancement) scores while revealing longer average text spans (4.520 tokens, 0.978–2.080 increase) at lower thresholds, indicating effective detection of low-support yet semantically substantial hotspots. Notably, DMoGL maintains performance stability with increasing corpus sizes (5,000 to large-scale datasets), showing slight improvements in recall and F1, while large language models fail to demonstrate competitive advantages. Ablation studies confirm the critical roles of the local mining layer and global-local fusion module, with domain insensitivity verified across diverse datasets. This work advances text analysis by bridging the fragmentation-precision gap in large-scale news processing through a novel global-local fusion methodology.
